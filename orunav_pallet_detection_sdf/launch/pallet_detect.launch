<launch>
  <group ns="robot4">
    <param name="tf_prefix" value="robot4" />
    <node pkg="orunav_pallet_detection_sdf" type="euro_pallet_sdf_node" name="euro_pallet_sdf_node" output="screen">
      
      <param name="robot_id_" value="4"/>
      <param name="pallet_name" value="full_pallet"/>
      <param name="using_bagfile" value="false"/>

    <!-- ==================== SDF Based Start ==================== -->    

      <remap from="pointcloud" to ="/robot4/sensors/asus_fork/depth_registered/points"/> 
      <param name="depth_frame_id" value="camera_depth_frame" />

      <param name="background_indices_file_name" value="/home/iliad/workspace/iliad_ws/src/navigation_oru/orunav_pallet_detection_sdf/data/background.dat"/>
      <param name="Dmax" value="0.4"/>
      <param name="visualize" value="true"/>
      <param name="visualize_sdf" value="true"/>
      <param name="removeFloor" value="true"/>
      <param name="sensor_time_offset" value="0.0"/>
      <param name="residual_thresh" value="0.01"/>
      <param name="cov_thresh" value="0.2"/>
      <param name="only_compute_filter_used" value="true"/>
      <param name="asus_camera" value="true" />
      <param name="min_nb_matched_points" value="10000" />
      <param name="min_match_nb_points_ratio" value="0.1" />
      <param name="floor_distance_thresh" value="0.02"/>
    
    <!-- ==================== SDF Based Finish ==================== -->


    <!-- =================== OBBICP Based Start =================== -->
      <param name="OBBICP_based_" value="true"/>

      <remap from="pointcloud" to ="/robot4/sensors/asus_fork/depth/points"/>
      <remap from="depthmap" to ="/robot4/sensors/asus_fork/depth/image"/>
      
      <param name="ground_depthmap_dir" value="/home/iliad/workspace/iliad_ws/src/navigation_oru/orunav_pallet_detection_sdf/data/ground_depth.png"/>
      <param name="models_dir" value="/home/iliad/workspace/iliad_ws/src/navigation_oru/orunav_pallet_detection_sdf/data/"/>

      <param name="downsample" value="true"/>
      <param name="downsample_ratio" value="0.02"/>

      <!-- For pclEuclideanDistanceSegmentation -->
      <param name="EC_segThresh" value="0.05"/>
      <param name="maxSegPoints" value="9900000"/>
      <param name="minSegPoints" value="100"/>

      <!-- For obbDimensionalCheck -->
      <param name="tolerance_X" value="0.2"/>
      <param name="tolerance_Y" value="0.2"/>
      <param name="tolerance_Z" value="0.3"/>

      <!-- Coarse to Fine Registration -->
      <param name="ICP_based" value="true"/>
      <param name="overlap_dst_thresh" value="0.05"/>
      <param name="overlap_score_thresh" value="0.8"/>

      <!-- Deep Learning -->
      <param name="deepLearning_based" value="false"/> 
      <remap from="semanticmap" to ="deepSeg/semantic_image"/>

      <param name="save_ground_depthmap" value="false"/>
      <param name="background_thresh" value="0.1"/>

      <param name="visual_model" value="true"/>

      <!-- =================== OBBICP Based Finish =================== -->

    </node>
  </group>
   
   <!-- Only work for online camera -->
  <node pkg="tf" type="static_transform_publisher" name="robotX_ASUS_4" args="0.699653 -0.0449958 0.829989 -0.294465 0.00655594 0.955638 0.00202011 world robot4/asus_fork_link 10"/>
  <node pkg="tf" type="static_transform_publisher" name="world_robot4" args="0 0 0 0 0 0 world /base_link 10"/>
  
  <!-- <node name="rviz" pkg="rviz" type="rviz" args="-d $(find orunav_pallet_detection_sdf)/launch/pallet_detect.rviz"/>
 -->
</launch>